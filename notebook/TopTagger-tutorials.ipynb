{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install git+https://github.com/xju2/root_gnn.git@release2.0"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating graphs using networkx\n",
    "\n",
    "[networkx](https://networkx.org/documentation/stable/tutorial.html) is a Python package for the study of graphs.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf\n",
    "from graph_nets import graphs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g = nx.DiGraph()\n",
    "\n",
    "# add nodes\n",
    "[g.add_node(idx, features=np.array([1.*idx])) for idx in range(4)];\n",
    "\n",
    "# add edges\n",
    "edge_lists = [(0, 1), (1, 2), (2, 3), (3, 0)]\n",
    "[g.add_edge(i, j, features=np.array([abs(i-j)])) for i,j in edge_lists];"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "pos = nx.spring_layout(g)\n",
    "nx.draw(g, pos, node_size=400, alpha=0.85, node_color=\"#1f78b4\", with_labels=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "obtain the adjacency matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adj = np.asarray(nx.to_numpy_matrix(g))\n",
    "adj"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g.edges()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g_tuple = utils_np.networkxs_to_graphs_tuple([g])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g_tuple"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def print_graphs_tuple(g, data=True):\n",
    "    for field_name in graphs.ALL_FIELDS:\n",
    "        per_replica_sample = getattr(g, field_name)\n",
    "        if per_replica_sample is None:\n",
    "            print(field_name, \"EMPTY\")\n",
    "        else:\n",
    "            print(field_name, \"is with shape\", per_replica_sample.shape)\n",
    "            if data and  field_name != \"edges\":\n",
    "                print(per_replica_sample)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print_graphs_tuple(g_tuple)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create GraphsTuple using data-dict \\[recommend\\]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_node = 4\n",
    "n_node_features = 1\n",
    "n_edge = 4\n",
    "n_edge_features = 1\n",
    "nodes = np.random.rand(n_node, n_node_features).astype(np.float32)\n",
    "edges = np.random.rand(n_edge, n_edge_features).astype(np.float32)\n",
    "receivers = np.array([1, 2, 3, 0])\n",
    "senders = np.array([0, 1, 2, 3])\n",
    "datadict = {\n",
    "    \"n_node\": n_node,\n",
    "    \"n_edge\": n_edge,\n",
    "    \"nodes\": nodes,\n",
    "    \"edges\": edges,\n",
    "    \"senders\": senders,\n",
    "    \"receivers\": receivers,\n",
    "    \"globals\": np.array([0], dtype=np.float32)\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g_tuple2 = utils_tf.data_dicts_to_graphs_tuple([datadict])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print_graphs_tuple(g_tuple2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Can you finish implementing the following function?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def fully_connected_edges(n_nodes: int):\n",
    "    \"\"\"For a given number of nodes, \n",
    "    return the senders and receivers for a fully-connected graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    receivers = senders = n_edge = None\n",
    "    \n",
    "    return {\"receivers\": receivers, \"senders\": senders, \"n_edge\": n_edge}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert an event to a fully-connected graph"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filename = '/global/homes/x/xju/atlas/data/top-tagger/test.h5'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with pd.HDFStore(filename, mode='r') as store:\n",
    "    df = store['table']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df[df['is_signal_new'] == 1].head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "event = df.iloc[0]\n",
    "event"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import itertools\n",
    "from typing import Optional\n",
    "\n",
    "features = ['E', 'PX', 'PY', 'PZ']\n",
    "scale = 0.001\n",
    "solution = 'is_signal_new'\n",
    "\n",
    "def make_graph(event, debug: Optional[bool] = False):\n",
    "    n_max_nodes = 200\n",
    "    n_nodes = 0\n",
    "    nodes = []\n",
    "    for inode in range(n_max_nodes):\n",
    "        E_name = 'E_{}'.format(inode)\n",
    "        if event[E_name] < 0.1:\n",
    "            continue\n",
    "\n",
    "        f_keynames = ['{}_{}'.format(x, inode) for x in features]\n",
    "        n_nodes += 1\n",
    "        nodes.append(event[f_keynames].values*scale)\n",
    "    nodes = np.array(nodes, dtype=np.float32)\n",
    "    # print(n_nodes, \"nodes\")\n",
    "    # print(\"node features:\", nodes.shape)\n",
    "\n",
    "    # edges 1) fully connected, 2) objects nearby in eta/phi are connected\n",
    "    # TODO: implement 2). <xju>\n",
    "    all_edges = list(itertools.combinations(range(n_nodes), 2))\n",
    "    senders = np.array([x[0] for x in all_edges])\n",
    "    receivers = np.array([x[1] for x in all_edges])\n",
    "    n_edges = len(all_edges)\n",
    "    edges = np.expand_dims(np.array([0.0]*n_edges, dtype=np.float32), axis=1)\n",
    "    # print(n_edges, \"edges\")\n",
    "    # print(\"senders:\", senders)\n",
    "    # print(\"receivers:\", receivers)\n",
    "\n",
    "    input_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([n_nodes], dtype=np.float32)\n",
    "    }\n",
    "    target_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([event[solution]], dtype=np.float32)\n",
    "    }\n",
    "    input_graph = utils_tf.data_dicts_to_graphs_tuple([input_datadict])\n",
    "    target_graph = utils_tf.data_dicts_to_graphs_tuple([target_datadict])\n",
    "    return [(input_graph, target_graph)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "graphs = make_graph(event)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g_evt_input, g_evt_target = graphs[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print_graphs_tuple(g_evt_input, data=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "17*16//2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g_evt_target.globals"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Graph Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----------------------------------\n",
    "```python\n",
    "\n",
    "NUM_LAYERS = 2 \n",
    "def make_mlp_model():\n",
    "  \"\"\"Instantiates a new MLP, followed by LayerNorm.\n",
    "\n",
    "  The parameters of each new MLP are not shared with others generated by\n",
    "  this function.\n",
    "\n",
    "  Returns:\n",
    "    A Sonnet module which contains the MLP and LayerNorm.\n",
    "  \"\"\"\n",
    "  # the activation function choices:\n",
    "  # swish, relu, relu6, leaky_relu\n",
    "  return snt.Sequential([\n",
    "      snt.nets.MLP([128, 64]*NUM_LAYERS,\n",
    "                    activation=tf.nn.relu,\n",
    "                    activate_final=True, \n",
    "                  #  dropout_rate=DROPOUT_RATE\n",
    "        ),\n",
    "      snt.LayerNorm(axis=-1, create_scale=True, create_offset=False)\n",
    "  ])\n",
    "```\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "import sonnet as snt\n",
    "\n",
    "from graph_nets import utils_tf\n",
    "from graph_nets import modules\n",
    "from graph_nets import blocks\n",
    "\n",
    "from root_gnn.src.models.base import MLPGraphNetwork\n",
    "from root_gnn.src.models.base import make_mlp_model\n",
    "\n",
    "LATENT_SIZE = 128\n",
    "\n",
    "class GlobalClassifierNoEdgeInfo(snt.Module):\n",
    "\n",
    "    def __init__(self, name=\"GlobalClassifierNoEdgeInfo\"):\n",
    "        super(GlobalClassifierNoEdgeInfo, self).__init__(name=name)\n",
    "\n",
    "        self._edge_block = blocks.EdgeBlock(\n",
    "            edge_model_fn=make_mlp_model,\n",
    "            use_edges=False,\n",
    "            use_receiver_nodes=True,\n",
    "            use_sender_nodes=True,\n",
    "            use_globals=False,\n",
    "            name='edge_encoder_block')\n",
    "\n",
    "        self._node_encoder_block = blocks.NodeBlock(\n",
    "            node_model_fn=make_mlp_model,\n",
    "            use_received_edges=False,\n",
    "            use_sent_edges=False,\n",
    "            use_nodes=True,\n",
    "            use_globals=False,\n",
    "            name='node_encoder_block'\n",
    "        )\n",
    "\n",
    "        self._global_block = blocks.GlobalBlock(\n",
    "            global_model_fn=make_mlp_model,\n",
    "            use_edges=True,\n",
    "            use_nodes=True,\n",
    "            use_globals=False,\n",
    "        )\n",
    "        \n",
    "        self._core = MLPGraphNetwork()\n",
    "        # Transforms the outputs into appropriate shapes.\n",
    "        global_output_size = 1\n",
    "        global_fn =lambda: snt.Sequential([\n",
    "            snt.nets.MLP([LATENT_SIZE, global_output_size],\n",
    "                         name='global_output'), tf.sigmoid])\n",
    "\n",
    "        self._output_transform = modules.GraphIndependent(None, None, global_fn)\n",
    "\n",
    "    def __call__(self, input_op, num_processing_steps):\n",
    "        latent = self._global_block(self._edge_block(self._node_encoder_block(input_op)))\n",
    "        latent0 = latent\n",
    "\n",
    "        output_ops = []\n",
    "        for _ in range(num_processing_steps):\n",
    "            core_input = utils_tf.concat([latent0, latent], axis=1)\n",
    "            latent = self._core(core_input)\n",
    "            output_ops.append(self._output_transform(latent))\n",
    "\n",
    "        return output_ops\n",
    "```\n",
    "-----------------------------------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Training GNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from root_gnn import model as all_models\n",
    "import sonnet as snt\n",
    "from root_gnn import losses"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = all_models.GlobalClassifierNoEdgeInfo()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_processing_steps_tr = 10\n",
    "outputs_tr = model(g_evt_input, num_processing_steps_tr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "outputs_tr[-1].globals"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g_evt_target.globals"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss_fcn = losses.GlobalLoss(real_global_weight=1., fake_global_weight=1.)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss_fcn(g_evt_target, outputs_tr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "learning_rate = 0.0005\n",
    "optimizer = snt.optimizers.Adam(learning_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```python\n",
    "@functools.partial(tf.function, input_signature=input_signature)\n",
    "def update_step(inputs_tr, targets_tr):\n",
    "    print(\"Tracing update_step\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs_tr = model(inputs_tr, num_processing_steps_tr)\n",
    "        loss_ops_tr = loss_fcn(targets_tr, outputs_tr)\n",
    "        loss_op_tr = tf.math.reduce_sum(loss_ops_tr) / tf.constant(num_processing_steps_tr, dtype=tf.float32)\n",
    "\n",
    "    gradients = tape.gradient(loss_op_tr, model.trainable_variables)\n",
    "    optimizer.apply(gradients, model.trainable_variables)\n",
    "    return outputs_tr, loss_op_tr\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Evaluating GNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a-Tutorial",
   "language": "python",
   "name": "tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}