{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf\n",
    "from graph_nets import graphs as Graphs\n",
    "\n",
    "import itertools\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graphs_tuple(g, data=True):\n",
    "    for field_name in Graphs.ALL_FIELDS:\n",
    "        per_replica_sample = getattr(g, field_name)\n",
    "        if per_replica_sample is None:\n",
    "            print(field_name, \"EMPTY\")\n",
    "        else:\n",
    "            print(field_name, \"is with shape\", per_replica_sample.shape)\n",
    "            if data and  field_name != \"edges\":\n",
    "                print(per_replica_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating graphs from networkx\n",
    "\n",
    "[networkx](https://networkx.org/documentation/stable/tutorial.html) is a Python package for the study of graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "\n",
    "# add nodes\n",
    "[g.add_node(idx, features=np.array([1.*idx])) for idx in range(4)];\n",
    "\n",
    "# add edges\n",
    "edge_lists = [(0, 1), (1, 2), (2, 3), (3, 0)]\n",
    "[g.add_edge(i, j, features=np.array([abs(i-j)])) for i,j in edge_lists];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "pos = nx.spring_layout(g)\n",
    "nx.draw(g, pos, node_size=400, alpha=0.85, node_color=\"#1f78b4\", with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtain the adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = np.asarray(nx.to_numpy_matrix(g))\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([(0, 1), (1, 2), (2, 3), (3, 0)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tuple = utils_np.networkxs_to_graphs_tuple([g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphsTuple(nodes=array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.]]), edges=array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3]]), receivers=array([1, 2, 3, 0], dtype=int32), senders=array([0, 1, 2, 3], dtype=int32), globals=None, n_node=array([4], dtype=int32), n_edge=array([4], dtype=int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes is with shape (4, 1)\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]]\n",
      "edges is with shape (4, 1)\n",
      "receivers is with shape (4,)\n",
      "[1 2 3 0]\n",
      "senders is with shape (4,)\n",
      "[0 1 2 3]\n",
      "globals EMPTY\n",
      "n_node is with shape (1,)\n",
      "[4]\n",
      "n_edge is with shape (1,)\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "print_graphs_tuple(g_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create GraphsTuple using data-dict \\[recommend\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node = 4\n",
    "n_node_features = 1\n",
    "n_edge = 4\n",
    "n_edge_features = 1\n",
    "nodes = np.random.rand(n_node, n_node_features).astype(np.float32)\n",
    "edges = np.random.rand(n_edge, n_edge_features).astype(np.float32)\n",
    "receivers = np.array([1, 2, 3, 0])\n",
    "senders = np.array([0, 1, 2, 3])\n",
    "datadict = {\n",
    "    \"n_node\": n_node,\n",
    "    \"n_edge\": n_edge,\n",
    "    \"nodes\": nodes,\n",
    "    \"edges\": edges,\n",
    "    \"senders\": senders,\n",
    "    \"receivers\": receivers,\n",
    "    \"globals\": np.array([0], dtype=np.float32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tuple2 = utils_tf.data_dicts_to_graphs_tuple([datadict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes is with shape (4, 1)\n",
      "tf.Tensor(\n",
      "[[0.88552785]\n",
      " [0.37593594]\n",
      " [0.58647484]\n",
      " [0.03406973]], shape=(4, 1), dtype=float32)\n",
      "edges is with shape (4, 1)\n",
      "receivers is with shape (4,)\n",
      "tf.Tensor([1 2 3 0], shape=(4,), dtype=int32)\n",
      "senders is with shape (4,)\n",
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int32)\n",
      "globals is with shape (1, 1)\n",
      "tf.Tensor([[0.]], shape=(1, 1), dtype=float32)\n",
      "n_node is with shape (1,)\n",
      "tf.Tensor([4], shape=(1,), dtype=int32)\n",
      "n_edge is with shape (1,)\n",
      "tf.Tensor([4], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print_graphs_tuple(g_tuple2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert an event to a fully-connected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/global/homes/x/xju/atlas/data/top-tagger/test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename, mode='r') as store:\n",
    "    df = store['table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_0</th>\n",
       "      <th>PX_0</th>\n",
       "      <th>PY_0</th>\n",
       "      <th>PZ_0</th>\n",
       "      <th>E_1</th>\n",
       "      <th>PX_1</th>\n",
       "      <th>PY_1</th>\n",
       "      <th>PZ_1</th>\n",
       "      <th>E_2</th>\n",
       "      <th>PX_2</th>\n",
       "      <th>...</th>\n",
       "      <th>E_199</th>\n",
       "      <th>PX_199</th>\n",
       "      <th>PY_199</th>\n",
       "      <th>PZ_199</th>\n",
       "      <th>truthE</th>\n",
       "      <th>truthPX</th>\n",
       "      <th>truthPY</th>\n",
       "      <th>truthPZ</th>\n",
       "      <th>ttv</th>\n",
       "      <th>is_signal_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>218.364243</td>\n",
       "      <td>-172.341858</td>\n",
       "      <td>110.129105</td>\n",
       "      <td>-76.503624</td>\n",
       "      <td>153.661118</td>\n",
       "      <td>-111.320465</td>\n",
       "      <td>93.167969</td>\n",
       "      <td>-50.390713</td>\n",
       "      <td>76.708054</td>\n",
       "      <td>-56.523701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>122.238762</td>\n",
       "      <td>26.738468</td>\n",
       "      <td>-91.613998</td>\n",
       "      <td>76.382225</td>\n",
       "      <td>121.227135</td>\n",
       "      <td>17.644758</td>\n",
       "      <td>-93.015450</td>\n",
       "      <td>75.715302</td>\n",
       "      <td>90.420105</td>\n",
       "      <td>21.377417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>383.772308</td>\n",
       "      <td>-97.906456</td>\n",
       "      <td>79.640709</td>\n",
       "      <td>-362.426361</td>\n",
       "      <td>200.625992</td>\n",
       "      <td>-54.921326</td>\n",
       "      <td>37.994343</td>\n",
       "      <td>-189.184753</td>\n",
       "      <td>123.247223</td>\n",
       "      <td>-33.828953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>132.492752</td>\n",
       "      <td>-77.763947</td>\n",
       "      <td>-87.322601</td>\n",
       "      <td>-62.304600</td>\n",
       "      <td>83.946594</td>\n",
       "      <td>-49.450481</td>\n",
       "      <td>-53.823605</td>\n",
       "      <td>-41.288010</td>\n",
       "      <td>28.072624</td>\n",
       "      <td>-19.964916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>730.786987</td>\n",
       "      <td>-209.120010</td>\n",
       "      <td>-193.454315</td>\n",
       "      <td>-672.973877</td>\n",
       "      <td>225.477325</td>\n",
       "      <td>-75.363350</td>\n",
       "      <td>-66.226990</td>\n",
       "      <td>-201.926651</td>\n",
       "      <td>217.040192</td>\n",
       "      <td>-63.698189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            E_0        PX_0        PY_0        PZ_0         E_1        PX_1  \\\n",
       "436  218.364243 -172.341858  110.129105  -76.503624  153.661118 -111.320465   \n",
       "440  122.238762   26.738468  -91.613998   76.382225  121.227135   17.644758   \n",
       "441  383.772308  -97.906456   79.640709 -362.426361  200.625992  -54.921326   \n",
       "444  132.492752  -77.763947  -87.322601  -62.304600   83.946594  -49.450481   \n",
       "445  730.786987 -209.120010 -193.454315 -672.973877  225.477325  -75.363350   \n",
       "\n",
       "          PY_1        PZ_1         E_2       PX_2  ...  E_199  PX_199  PY_199  \\\n",
       "436  93.167969  -50.390713   76.708054 -56.523701  ...    0.0     0.0     0.0   \n",
       "440 -93.015450   75.715302   90.420105  21.377417  ...    0.0     0.0     0.0   \n",
       "441  37.994343 -189.184753  123.247223 -33.828953  ...    0.0     0.0     0.0   \n",
       "444 -53.823605  -41.288010   28.072624 -19.964916  ...    0.0     0.0     0.0   \n",
       "445 -66.226990 -201.926651  217.040192 -63.698189  ...    0.0     0.0     0.0   \n",
       "\n",
       "     PZ_199  truthE  truthPX  truthPY  truthPZ  ttv  is_signal_new  \n",
       "436     0.0     0.0      0.0      0.0      0.0    1              0  \n",
       "440     0.0     0.0      0.0      0.0      0.0    1              0  \n",
       "441     0.0     0.0      0.0      0.0      0.0    1              0  \n",
       "444     0.0     0.0      0.0      0.0      0.0    1              0  \n",
       "445     0.0     0.0      0.0      0.0      0.0    1              0  \n",
       "\n",
       "[5 rows x 806 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_0</th>\n",
       "      <th>PX_0</th>\n",
       "      <th>PY_0</th>\n",
       "      <th>PZ_0</th>\n",
       "      <th>E_1</th>\n",
       "      <th>PX_1</th>\n",
       "      <th>PY_1</th>\n",
       "      <th>PZ_1</th>\n",
       "      <th>E_2</th>\n",
       "      <th>PX_2</th>\n",
       "      <th>...</th>\n",
       "      <th>E_199</th>\n",
       "      <th>PX_199</th>\n",
       "      <th>PY_199</th>\n",
       "      <th>PZ_199</th>\n",
       "      <th>truthE</th>\n",
       "      <th>truthPX</th>\n",
       "      <th>truthPY</th>\n",
       "      <th>truthPZ</th>\n",
       "      <th>ttv</th>\n",
       "      <th>is_signal_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>65.646370</td>\n",
       "      <td>-58.526817</td>\n",
       "      <td>29.698223</td>\n",
       "      <td>-1.439855</td>\n",
       "      <td>64.047226</td>\n",
       "      <td>-36.257854</td>\n",
       "      <td>46.957092</td>\n",
       "      <td>24.133938</td>\n",
       "      <td>46.889977</td>\n",
       "      <td>-26.141216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>609.978516</td>\n",
       "      <td>-425.223938</td>\n",
       "      <td>360.547333</td>\n",
       "      <td>179.307800</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>182.433838</td>\n",
       "      <td>-67.388512</td>\n",
       "      <td>-150.770279</td>\n",
       "      <td>77.519150</td>\n",
       "      <td>105.039909</td>\n",
       "      <td>-24.843391</td>\n",
       "      <td>-70.149010</td>\n",
       "      <td>74.130325</td>\n",
       "      <td>99.697556</td>\n",
       "      <td>-25.996574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>761.416626</td>\n",
       "      <td>-368.340454</td>\n",
       "      <td>-444.232635</td>\n",
       "      <td>466.554565</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>218.015808</td>\n",
       "      <td>-142.368179</td>\n",
       "      <td>19.166389</td>\n",
       "      <td>-163.996475</td>\n",
       "      <td>151.196808</td>\n",
       "      <td>-75.772964</td>\n",
       "      <td>7.036884</td>\n",
       "      <td>-130.649979</td>\n",
       "      <td>64.975327</td>\n",
       "      <td>-49.838360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1055.739014</td>\n",
       "      <td>-647.505615</td>\n",
       "      <td>54.828110</td>\n",
       "      <td>-814.257935</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>116.801796</td>\n",
       "      <td>90.702217</td>\n",
       "      <td>-54.621929</td>\n",
       "      <td>49.317455</td>\n",
       "      <td>87.957840</td>\n",
       "      <td>44.834236</td>\n",
       "      <td>-44.274315</td>\n",
       "      <td>61.369846</td>\n",
       "      <td>66.443222</td>\n",
       "      <td>31.902834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>669.998962</td>\n",
       "      <td>439.078888</td>\n",
       "      <td>-269.705780</td>\n",
       "      <td>392.723145</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>114.989540</td>\n",
       "      <td>-70.048080</td>\n",
       "      <td>-66.881485</td>\n",
       "      <td>-61.989738</td>\n",
       "      <td>74.398933</td>\n",
       "      <td>-57.145046</td>\n",
       "      <td>-44.540745</td>\n",
       "      <td>-16.904631</td>\n",
       "      <td>48.529976</td>\n",
       "      <td>-37.200237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>803.532227</td>\n",
       "      <td>-520.018433</td>\n",
       "      <td>-429.099030</td>\n",
       "      <td>-403.125366</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            E_0        PX_0        PY_0        PZ_0         E_1       PX_1  \\\n",
       "275   65.646370  -58.526817   29.698223   -1.439855   64.047226 -36.257854   \n",
       "278  182.433838  -67.388512 -150.770279   77.519150  105.039909 -24.843391   \n",
       "285  218.015808 -142.368179   19.166389 -163.996475  151.196808 -75.772964   \n",
       "302  116.801796   90.702217  -54.621929   49.317455   87.957840  44.834236   \n",
       "308  114.989540  -70.048080  -66.881485  -61.989738   74.398933 -57.145046   \n",
       "\n",
       "          PY_1        PZ_1        E_2       PX_2  ...  E_199  PX_199  PY_199  \\\n",
       "275  46.957092   24.133938  46.889977 -26.141216  ...    0.0     0.0     0.0   \n",
       "278 -70.149010   74.130325  99.697556 -25.996574  ...    0.0     0.0     0.0   \n",
       "285   7.036884 -130.649979  64.975327 -49.838360  ...    0.0     0.0     0.0   \n",
       "302 -44.274315   61.369846  66.443222  31.902834  ...    0.0     0.0     0.0   \n",
       "308 -44.540745  -16.904631  48.529976 -37.200237  ...    0.0     0.0     0.0   \n",
       "\n",
       "     PZ_199       truthE     truthPX     truthPY     truthPZ  ttv  \\\n",
       "275     0.0   609.978516 -425.223938  360.547333  179.307800    1   \n",
       "278     0.0   761.416626 -368.340454 -444.232635  466.554565    1   \n",
       "285     0.0  1055.739014 -647.505615   54.828110 -814.257935    1   \n",
       "302     0.0   669.998962  439.078888 -269.705780  392.723145    1   \n",
       "308     0.0   803.532227 -520.018433 -429.099030 -403.125366    1   \n",
       "\n",
       "     is_signal_new  \n",
       "275              1  \n",
       "278              1  \n",
       "285              1  \n",
       "302              1  \n",
       "308              1  \n",
       "\n",
       "[5 rows x 806 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['is_signal_new'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E_0              218.364243\n",
       "PX_0            -172.341858\n",
       "PY_0             110.129105\n",
       "PZ_0             -76.503624\n",
       "E_1              153.661118\n",
       "                    ...    \n",
       "truthPX            0.000000\n",
       "truthPY            0.000000\n",
       "truthPZ            0.000000\n",
       "ttv                1.000000\n",
       "is_signal_new      0.000000\n",
       "Name: 436, Length: 806, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event = df.iloc[0]\n",
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['E', 'PX', 'PY', 'PZ']\n",
    "scale = 0.001\n",
    "solution = 'is_signal_new'\n",
    "\n",
    "def make_graph(event, debug: Optional[bool] = False):\n",
    "    n_max_nodes = 200\n",
    "    n_nodes = 0\n",
    "    nodes = []\n",
    "    for inode in range(n_max_nodes):\n",
    "        E_name = 'E_{}'.format(inode)\n",
    "        if event[E_name] < 0.1:\n",
    "            continue\n",
    "\n",
    "        f_keynames = ['{}_{}'.format(x, inode) for x in features]\n",
    "        n_nodes += 1\n",
    "        nodes.append(event[f_keynames].values*scale)\n",
    "    nodes = np.array(nodes, dtype=np.float32)\n",
    "\n",
    "    # to make a bi-directional fully connected graph\n",
    "    all_edges = list(itertools.combinations(range(n_nodes), 2))\n",
    "    senders = np.array([x[0] for x in all_edges])\n",
    "    receivers = np.array([x[1] for x in all_edges])\n",
    "    n_edges = len(all_edges)\n",
    "    edges = np.expand_dims(np.array([0.0]*n_edges, dtype=np.float32), axis=1)\n",
    "\n",
    "    input_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([n_nodes], dtype=np.float32)\n",
    "    }\n",
    "    target_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([event[solution]], dtype=np.float32)\n",
    "    }\n",
    "    input_graph = utils_tf.data_dicts_to_graphs_tuple([input_datadict])\n",
    "    target_graph = utils_tf.data_dicts_to_graphs_tuple([target_datadict])\n",
    "    return [(input_graph, target_graph)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = make_graph(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_evt_input, g_evt_target = graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes is with shape (17, 4)\n",
      "edges is with shape (136, 1)\n",
      "receivers is with shape (136,)\n",
      "senders is with shape (136,)\n",
      "globals is with shape (1, 1)\n",
      "n_node is with shape (1,)\n",
      "n_edge is with shape (1,)\n"
     ]
    }
   ],
   "source": [
    "print_graphs_tuple(g_evt_input, data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17*16//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_evt_target.globals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all events into graphs and save these graphs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(filename):\n",
    "    with pd.HDFStore(filename, mode='r') as store:\n",
    "        df = store['table']\n",
    "\n",
    "    for ievt in range(df.shape[0]):\n",
    "        yield df.iloc[ievt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from root_gnn.src.datasets.base import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopTaggerDataset(DataSet):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.read = read\n",
    "        self.make_graph = make_graph\n",
    "\n",
    "    def _num_evts(self, filename):\n",
    "        with pd.HDFStore(filename, mode='r') as store:\n",
    "            df = store['table']\n",
    "        return df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TopTaggerDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_filename = '/global/homes/x/xju/atlas/data/top-tagger/train.h5'\n",
    "n_evts_per_record = 1000\n",
    "debug = False\n",
    "max_evts = 10000\n",
    "num_workers = 1\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 10,000 events are requested to be written to 10 files with 1 workers\n",
      "TopTaggerDataset added 10,000 events, in 10.1 mins\n",
      "0 events failed in being converted to graph\n"
     ]
    }
   ],
   "source": [
    "# using multiprocessing in jupyter notebook seems problematic..\n",
    "data.process(filename=tr_filename, outname=\"TopTagger/trainning\",\\\n",
    "    n_evts_per_record=n_evts_per_record, debug=debug,\n",
    "    max_evts=max_evts, num_workers=num_workers, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning_0.tfrec  trainning_3.tfrec  trainning_6.tfrec  trainning_9.tfrec\n",
      "trainning_1.tfrec  trainning_4.tfrec  trainning_7.tfrec\n",
      "trainning_2.tfrec  trainning_5.tfrec  trainning_8.tfrec\n"
     ]
    }
   ],
   "source": [
    "!ls TopTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-01 15:51:15.248901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Shuffling input files\n",
      "Total 10 files\n",
      "Training   8 files\n",
      "Validation 1 files\n",
      "Testing    1 files\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/x/xju/.conda/envs/tf2.4/bin/split_files_for_nn\", line 62, in <module>\n",
      "    split(**args.__dict__)\n",
      "  File \"/global/homes/x/xju/.conda/envs/tf2.4/bin/split_files_for_nn\", line 41, in split\n",
      "    my_copy(file_name, dest)\n",
      "  File \"/global/homes/x/xju/.conda/envs/tf2.4/bin/split_files_for_nn\", line 9, in my_copy\n",
      "    os.symlink(os.path.abspath(src), dest)\n",
      "FileExistsError: [Errno 17] File exists: '/global/cfs/cdirs/atlas/xju/testarea/root_gnn/notebook/TopTagger/trainning_5.tfrec' -> 'inputs/train/trainning_5.tfrec'\n"
     ]
    }
   ],
   "source": [
    "!split_files_for_nn TopTagger inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train  val\n"
     ]
    }
   ],
   "source": [
    "!ls inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TF Version:2.4.1\n",
      "WARNING:tensorflow:No horvod module, cannot perform distributed training\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf\n",
    "from graph_nets import graphs as Graphs\n",
    "import sonnet as snt\n",
    "\n",
    "import itertools\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "from root_gnn import model as Models\n",
    "from root_gnn import losses\n",
    "from root_gnn.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module root_gnn.model in root_gnn:\n",
      "\n",
      "NAME\n",
      "    root_gnn.model\n",
      "\n",
      "DESCRIPTION\n",
      "    The implementation of Graph Networks are mostly inspired by the ones in deepmind/graphs_nets\n",
      "    https://github.com/deepmind/graph_nets\n",
      "\n",
      "CLASSES\n",
      "    root_gnn.src.models.edge_learner.EdgeLearnerBase(sonnet.src.base.Module)\n",
      "        root_gnn.src.models.edge_learner.EdgeClassifier\n",
      "        root_gnn.src.models.edge_learner.EdgeRegression\n",
      "    root_gnn.src.models.global_learner.GlobalLearnerBase(sonnet.src.base.Module)\n",
      "        root_gnn.src.models.global_learner.GlobalClassifier\n",
      "        root_gnn.src.models.global_learner.GlobalRegression\n",
      "    \n",
      "    class EdgeClassifier(EdgeLearnerBase)\n",
      "     |  EdgeClassifier(*args, **kwargs) -> ~T\n",
      "     |  \n",
      "     |  Base class for Sonnet modules.\n",
      "     |  \n",
      "     |  A Sonnet module is a lightweight container for variables and other modules.\n",
      "     |  Modules typically define one or more \"forward\" methods (e.g. ``__call__``)\n",
      "     |  which apply operations combining user input and module parameters. For\n",
      "     |  example::\n",
      "     |  \n",
      "     |      >>> class MultiplyModule(snt.Module):\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(2., name='w')\n",
      "     |      ...     return x * self.w\n",
      "     |  \n",
      "     |      >>> mod = MultiplyModule()\n",
      "     |      >>> mod(1.)\n",
      "     |      <tf.Tensor: ... numpy=2.0>\n",
      "     |  \n",
      "     |  Sonnet modules are a layer on top of :tf:`Module`, implementing automatic name\n",
      "     |  scoping as described in the original RFC :cite:`agarwal2019stateful`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EdgeClassifier\n",
      "     |      EdgeLearnerBase\n",
      "     |      sonnet.src.base.Module\n",
      "     |      tensorflow.python.module.module.Module\n",
      "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      "     |      tensorflow.python.training.tracking.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, with_edge_inputs=False, with_node_inputs=True, encoder_size: list = None, core_size: list = None, decoder_size: list = None, name='EdgeClassifier', **kwargs)\n",
      "     |      Initializes the current module with the given name.\n",
      "     |      \n",
      "     |      Subclasses should call this constructor before creating other modules or\n",
      "     |      variables such that those modules are named correctly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: An optional string name for the class. Must be a valid Python\n",
      "     |          identifier. If ``name`` is not provided then the class name for the\n",
      "     |          current instance is converted to ``lower_snake_case`` and used instead.\n",
      "     |  \n",
      "     |  __repr__ lambda module\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from EdgeLearnerBase:\n",
      "     |  \n",
      "     |  __call__(self, input_op, num_processing_steps, is_training=True)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from sonnet.src.base.Module:\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.trainable_variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  with_name_scope(method) from sonnet.src.base.ModuleMetaclass\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      >>> class MyModule(tf.Module):\n",
      "     |      ...   @tf.Module.with_name_scope\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      "     |      ...     return tf.matmul(x, self.w)\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      >>> mod = MyModule()\n",
      "     |      >>> mod(tf.ones([1, 2]))\n",
      "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |      >>> mod.w\n",
      "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      "     |      numpy=..., dtype=float32)>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      >>> a = tf.Module()\n",
      "     |      >>> b = tf.Module()\n",
      "     |      >>> c = tf.Module()\n",
      "     |      >>> a.b = b\n",
      "     |      >>> b.c = c\n",
      "     |      >>> list(a.submodules) == [b, c]\n",
      "     |      True\n",
      "     |      >>> list(b.submodules) == [c]\n",
      "     |      True\n",
      "     |      >>> list(c.submodules) == []\n",
      "     |      True\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.training.tracking.tracking.AutoTrackable:\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class EdgeRegression(EdgeLearnerBase)\n",
      "     |  EdgeRegression(*args, **kwargs) -> ~T\n",
      "     |  \n",
      "     |  Base class for Sonnet modules.\n",
      "     |  \n",
      "     |  A Sonnet module is a lightweight container for variables and other modules.\n",
      "     |  Modules typically define one or more \"forward\" methods (e.g. ``__call__``)\n",
      "     |  which apply operations combining user input and module parameters. For\n",
      "     |  example::\n",
      "     |  \n",
      "     |      >>> class MultiplyModule(snt.Module):\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(2., name='w')\n",
      "     |      ...     return x * self.w\n",
      "     |  \n",
      "     |      >>> mod = MultiplyModule()\n",
      "     |      >>> mod(1.)\n",
      "     |      <tf.Tensor: ... numpy=2.0>\n",
      "     |  \n",
      "     |  Sonnet modules are a layer on top of :tf:`Module`, implementing automatic name\n",
      "     |  scoping as described in the original RFC :cite:`agarwal2019stateful`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EdgeRegression\n",
      "     |      EdgeLearnerBase\n",
      "     |      sonnet.src.base.Module\n",
      "     |      tensorflow.python.module.module.Module\n",
      "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      "     |      tensorflow.python.training.tracking.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, edge_output_size, with_edge_inputs=False, with_node_inputs=True, encoder_size: list = None, core_size: list = None, decoder_size: list = None, name='EdgeRegression', **kwargs)\n",
      "     |      Initializes the current module with the given name.\n",
      "     |      \n",
      "     |      Subclasses should call this constructor before creating other modules or\n",
      "     |      variables such that those modules are named correctly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: An optional string name for the class. Must be a valid Python\n",
      "     |          identifier. If ``name`` is not provided then the class name for the\n",
      "     |          current instance is converted to ``lower_snake_case`` and used instead.\n",
      "     |  \n",
      "     |  __repr__ lambda module\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from EdgeLearnerBase:\n",
      "     |  \n",
      "     |  __call__(self, input_op, num_processing_steps, is_training=True)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from sonnet.src.base.Module:\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.trainable_variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  with_name_scope(method) from sonnet.src.base.ModuleMetaclass\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      >>> class MyModule(tf.Module):\n",
      "     |      ...   @tf.Module.with_name_scope\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      "     |      ...     return tf.matmul(x, self.w)\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      >>> mod = MyModule()\n",
      "     |      >>> mod(tf.ones([1, 2]))\n",
      "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |      >>> mod.w\n",
      "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      "     |      numpy=..., dtype=float32)>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      >>> a = tf.Module()\n",
      "     |      >>> b = tf.Module()\n",
      "     |      >>> c = tf.Module()\n",
      "     |      >>> a.b = b\n",
      "     |      >>> b.c = c\n",
      "     |      >>> list(a.submodules) == [b, c]\n",
      "     |      True\n",
      "     |      >>> list(b.submodules) == [c]\n",
      "     |      True\n",
      "     |      >>> list(c.submodules) == []\n",
      "     |      True\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.training.tracking.tracking.AutoTrackable:\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GlobalClassifier(GlobalLearnerBase)\n",
      "     |  GlobalClassifier(*args, **kwargs) -> ~T\n",
      "     |  \n",
      "     |  Base class for Sonnet modules.\n",
      "     |  \n",
      "     |  A Sonnet module is a lightweight container for variables and other modules.\n",
      "     |  Modules typically define one or more \"forward\" methods (e.g. ``__call__``)\n",
      "     |  which apply operations combining user input and module parameters. For\n",
      "     |  example::\n",
      "     |  \n",
      "     |      >>> class MultiplyModule(snt.Module):\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(2., name='w')\n",
      "     |      ...     return x * self.w\n",
      "     |  \n",
      "     |      >>> mod = MultiplyModule()\n",
      "     |      >>> mod(1.)\n",
      "     |      <tf.Tensor: ... numpy=2.0>\n",
      "     |  \n",
      "     |  Sonnet modules are a layer on top of :tf:`Module`, implementing automatic name\n",
      "     |  scoping as described in the original RFC :cite:`agarwal2019stateful`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GlobalClassifier\n",
      "     |      GlobalLearnerBase\n",
      "     |      sonnet.src.base.Module\n",
      "     |      tensorflow.python.module.module.Module\n",
      "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      "     |      tensorflow.python.training.tracking.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, with_edge_inputs=False, with_node_inputs=True, with_global_inputs=False, encoder_size: list = None, core_size: list = None, decoder_size: list = None, name='GlobalClassifier', **kwargs)\n",
      "     |      Initializes the current module with the given name.\n",
      "     |      \n",
      "     |      Subclasses should call this constructor before creating other modules or\n",
      "     |      variables such that those modules are named correctly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: An optional string name for the class. Must be a valid Python\n",
      "     |          identifier. If ``name`` is not provided then the class name for the\n",
      "     |          current instance is converted to ``lower_snake_case`` and used instead.\n",
      "     |  \n",
      "     |  __repr__ lambda module\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GlobalLearnerBase:\n",
      "     |  \n",
      "     |  __call__(self, input_op, num_processing_steps, is_training=True)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from sonnet.src.base.Module:\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.trainable_variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  with_name_scope(method) from sonnet.src.base.ModuleMetaclass\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      >>> class MyModule(tf.Module):\n",
      "     |      ...   @tf.Module.with_name_scope\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      "     |      ...     return tf.matmul(x, self.w)\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      >>> mod = MyModule()\n",
      "     |      >>> mod(tf.ones([1, 2]))\n",
      "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |      >>> mod.w\n",
      "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      "     |      numpy=..., dtype=float32)>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      >>> a = tf.Module()\n",
      "     |      >>> b = tf.Module()\n",
      "     |      >>> c = tf.Module()\n",
      "     |      >>> a.b = b\n",
      "     |      >>> b.c = c\n",
      "     |      >>> list(a.submodules) == [b, c]\n",
      "     |      True\n",
      "     |      >>> list(b.submodules) == [c]\n",
      "     |      True\n",
      "     |      >>> list(c.submodules) == []\n",
      "     |      True\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.training.tracking.tracking.AutoTrackable:\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GlobalRegression(GlobalLearnerBase)\n",
      "     |  GlobalRegression(*args, **kwargs) -> ~T\n",
      "     |  \n",
      "     |  Base class for Sonnet modules.\n",
      "     |  \n",
      "     |  A Sonnet module is a lightweight container for variables and other modules.\n",
      "     |  Modules typically define one or more \"forward\" methods (e.g. ``__call__``)\n",
      "     |  which apply operations combining user input and module parameters. For\n",
      "     |  example::\n",
      "     |  \n",
      "     |      >>> class MultiplyModule(snt.Module):\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(2., name='w')\n",
      "     |      ...     return x * self.w\n",
      "     |  \n",
      "     |      >>> mod = MultiplyModule()\n",
      "     |      >>> mod(1.)\n",
      "     |      <tf.Tensor: ... numpy=2.0>\n",
      "     |  \n",
      "     |  Sonnet modules are a layer on top of :tf:`Module`, implementing automatic name\n",
      "     |  scoping as described in the original RFC :cite:`agarwal2019stateful`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GlobalRegression\n",
      "     |      GlobalLearnerBase\n",
      "     |      sonnet.src.base.Module\n",
      "     |      tensorflow.python.module.module.Module\n",
      "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      "     |      tensorflow.python.training.tracking.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, global_output_size, with_edge_inputs=False, with_node_inputs=True, with_global_inputs=False, encoder_size: list = None, core_size: list = None, decoder_size: list = None, name='GlobalRegression', **kwargs)\n",
      "     |      Initializes the current module with the given name.\n",
      "     |      \n",
      "     |      Subclasses should call this constructor before creating other modules or\n",
      "     |      variables such that those modules are named correctly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: An optional string name for the class. Must be a valid Python\n",
      "     |          identifier. If ``name`` is not provided then the class name for the\n",
      "     |          current instance is converted to ``lower_snake_case`` and used instead.\n",
      "     |  \n",
      "     |  __repr__ lambda module\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GlobalLearnerBase:\n",
      "     |  \n",
      "     |  __call__(self, input_op, num_processing_steps, is_training=True)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from sonnet.src.base.Module:\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.trainable_variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  with_name_scope(method) from sonnet.src.base.ModuleMetaclass\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      >>> class MyModule(tf.Module):\n",
      "     |      ...   @tf.Module.with_name_scope\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      "     |      ...     return tf.matmul(x, self.w)\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      >>> mod = MyModule()\n",
      "     |      >>> mod(tf.ones([1, 2]))\n",
      "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |      >>> mod.w\n",
      "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      "     |      numpy=..., dtype=float32)>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      >>> a = tf.Module()\n",
      "     |      >>> b = tf.Module()\n",
      "     |      >>> c = tf.Module()\n",
      "     |      >>> a.b = b\n",
      "     |      >>> b.c = c\n",
      "     |      >>> list(a.submodules) == [b, c]\n",
      "     |      True\n",
      "     |      >>> list(b.submodules) == [c]\n",
      "     |      True\n",
      "     |      >>> list(c.submodules) == []\n",
      "     |      True\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.training.tracking.tracking.AutoTrackable:\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ('EdgeClassifier', 'EdgeRegression', 'GlobalClassifier', 'Gl...\n",
      "\n",
      "FILE\n",
      "    /global/cfs/cdirs/atlas/xju/testarea/root_gnn/root_gnn/model.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GlobalRegression in module root_gnn.src.models.global_learner:\n",
      "\n",
      "class GlobalRegression(GlobalLearnerBase)\n",
      " |  GlobalRegression(*args, **kwargs) -> ~T\n",
      " |  \n",
      " |  Base class for Sonnet modules.\n",
      " |  \n",
      " |  A Sonnet module is a lightweight container for variables and other modules.\n",
      " |  Modules typically define one or more \"forward\" methods (e.g. ``__call__``)\n",
      " |  which apply operations combining user input and module parameters. For\n",
      " |  example::\n",
      " |  \n",
      " |      >>> class MultiplyModule(snt.Module):\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(2., name='w')\n",
      " |      ...     return x * self.w\n",
      " |  \n",
      " |      >>> mod = MultiplyModule()\n",
      " |      >>> mod(1.)\n",
      " |      <tf.Tensor: ... numpy=2.0>\n",
      " |  \n",
      " |  Sonnet modules are a layer on top of :tf:`Module`, implementing automatic name\n",
      " |  scoping as described in the original RFC :cite:`agarwal2019stateful`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GlobalRegression\n",
      " |      GlobalLearnerBase\n",
      " |      sonnet.src.base.Module\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, global_output_size, with_edge_inputs=False, with_node_inputs=True, with_global_inputs=False, encoder_size: list = None, core_size: list = None, decoder_size: list = None, name='GlobalRegression', **kwargs)\n",
      " |      Initializes the current module with the given name.\n",
      " |      \n",
      " |      Subclasses should call this constructor before creating other modules or\n",
      " |      variables such that those modules are named correctly.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: An optional string name for the class. Must be a valid Python\n",
      " |          identifier. If ``name`` is not provided then the class name for the\n",
      " |          current instance is converted to ``lower_snake_case`` and used instead.\n",
      " |  \n",
      " |  __repr__ lambda module\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from GlobalLearnerBase:\n",
      " |  \n",
      " |  __call__(self, input_op, num_processing_steps, is_training=True)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sonnet.src.base.Module:\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      " |      \n",
      " |      See :tf:`Module.trainable_variables` for implementation details.\n",
      " |      \n",
      " |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      " |      are called). As such just after construction there are typically no\n",
      " |      variables. To mitigate a common error (calling ``.variables`` or\n",
      " |      ``.trainable_variables`` before any variables are created) these properties\n",
      " |      will raise an exception if their result is empty. See\n",
      " |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  variables\n",
      " |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      " |      \n",
      " |      See :tf:`Module.variables` for implementation details.\n",
      " |      \n",
      " |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      " |      are called). As such just after construction there are typically no\n",
      " |      variables. To mitigate a common error (calling ``.variables`` or\n",
      " |      ``.trainable_variables`` before any variables are created) these properties\n",
      " |      will raise an exception if their result is empty. See\n",
      " |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from sonnet.src.base.ModuleMetaclass\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.training.tracking.tracking.AutoTrackable:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Models.GlobalRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Models.GlobalClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_processing_steps_tr = 2\n",
    "outputs_tr = model(g_evt_input, num_processing_steps_tr)\n",
    "\n",
    "outputs_tr[-1].globals\n",
    "\n",
    "g_evt_target.globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn = losses.GlobalLoss(real_global_weight=1., fake_global_weight=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss_fcn(g_evt_target, outputs_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "optimizer = snt.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning_0.tfrec  trainning_3.tfrec  trainning_5.tfrec  trainning_8.tfrec\n",
      "trainning_1.tfrec  trainning_4.tfrec  trainning_7.tfrec  trainning_9.tfrec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls inputs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading latest checkpoint from: TrainedResults/checkpoints\n"
     ]
    }
   ],
   "source": [
    "# mode, -> 'rgr,globals', ['clf', 'rgr'], ['globals', 'edges']\n",
    "trainer = Trainer(input_dir=\"inputs\", output_dir=\"TrainedResults\",\n",
    "                  model=model, loss_fcn=loss_fcn, optimizer=optimizer,\n",
    "                  evt_per_file=n_evts_per_record, mode='clf,globals', batch_size=10,\n",
    "                  val_batches=10, log_freq=10, patiences=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts with 80 graphs with batch size of 10 for 1 epochs\n",
      "runing 1000 steps, 8 steps per epoch, and stop on variable val_loss\n",
      "Tracing update_step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_3/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_3/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_3/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_3/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_2/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_2/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_2/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_2/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_1/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_1/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_1/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_1/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/edge_encoder_block/broadcast_receiver_nodes_to_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/edge_encoder_block/broadcast_receiver_nodes_to_edges/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/edge_encoder_block/broadcast_receiver_nodes_to_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/edge_encoder_block/broadcast_sender_nodes_to_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/edge_encoder_block/broadcast_sender_nodes_to_edges/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/edge_encoder_block/broadcast_sender_nodes_to_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing update_step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:16<4:27:07, 16.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>446,081 trainable parameters<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 40/1000 [00:57<06:32,  2.45it/s, acc=0.57, auc=0.637, loss=0.964, pre=0.481, rec=0.975, val_loss=0.669]/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 13%|█▎        | 130/1000 [02:04<13:55,  1.04it/s, acc=0.53, auc=0.632, loss=0.656, pre=0.459, rec=0.975, val_loss=0.694]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached maximum failed attempts: 10 attempts. Stopping training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add predictions\n",
    "# results = model(test_input_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a-TF2.4",
   "language": "python",
   "name": "tf2p4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
