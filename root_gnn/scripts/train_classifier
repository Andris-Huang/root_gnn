#!/usr/bin/env python
"""
Training GNN
"""

import tensorflow as tf

import os
import sys
import argparse

import re
import time
import random
import functools
import six

import numpy as np
import sklearn.metrics


from graph_nets import utils_tf
from graph_nets import utils_np
import sonnet as snt

from root_gnn import model as all_models
from root_gnn import losses
# from root_gnn import optimizers
from root_gnn.src.datasets import graph
from root_gnn.utils import load_yaml

from root_gnn import trainer 

if __name__ == "__main__":
    
    parser = argparse.ArgumentParser(description='Train nx-graph with configurations', parents=[trainer.TrainerBase.get_arg_parser()])
    add_arg = parser.add_argument
    add_arg("--model-name", help="model name", default="GlobalClassifierNoEdgeInfo")
    add_arg("--loss-name", help="loss function name", default="GlobalLoss,1,1")
    add_arg("--lr", type=float, help="optimizer learning rate", default=0.001)
    add_arg("--metric-mode", default="clf")
    add_arg("--early-stop", help="metric for early stop", default="auc")
    add_arg("--max-attempts", help="maximum failure threshold", default=1)
    args = parser.parse_args()

    config = vars(args)
    config["model"] = getattr(all_models, config["model_name"])()
    loss_config = config["loss_name"].split(',')
    config["loss_name"] = loss_config[0]
    config["loss_fcn"] = getattr(losses, loss_config[0])(*[float(x) for x in loss_config[1:]])

    # Here, if the user wants, they can add/modify config arguments to be loaded into TrainerBase
    # e.g.
    config["lr"] = 0.0005
    config["random_seed"] = 42
    
    print("Loading TrainerBase with the following configurations:", config)
    trnr = trainer.TrainerBase(**config)

    train_data, _ = trnr.load_training_data(shuffle=True)
    val_data, _ = trnr.load_validating_data(shuffle=True)

    trnr.train(config["model"], config["loss_fcn"], train_data)
    #trnr.train()
    # trnr.score(trainer.predict(val_data), truth_data, metric_fn)
